import pandas as pd
import requests
import time
from collections import defaultdict

def find_repo(df):
    """
    parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰repo_urlã‚’å–å¾—ã—ã€æœ€ã‚‚ã‚¹ã‚¿ãƒ¼æ•°ã®å¤šã„ãƒªãƒã‚¸ãƒˆãƒªã‚’è¡¨ç¤ºã™ã‚‹
    """
    # repo_urlã‹ã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—
    unique_repos = df['repo_url'].unique()
    
    repo_stars = {}
    failed_repos = []
    
    print(f"æ¤œç´¢å¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(unique_repos)}")
    
    for i, repo_url in enumerate(unique_repos):
        try:
            # GitHub URLã‹ã‚‰owner/repoã®å½¢å¼ã‚’æŠ½å‡º
            if 'github.com' in repo_url:
                parts = repo_url.replace('https://github.com/', '').replace('http://github.com/', '').split('/')
                if len(parts) >= 2:
                    owner = parts[0]
                    repo_name = parts[1]
                    
                    # GitHub APIå‘¼ã³å‡ºã—
                    api_url = f"https://api.github.com/repos/{owner}/{repo_name}"
                    response = requests.get(api_url)
                    
                    if response.status_code == 200:
                        repo_data = response.json()
                        stars = repo_data.get('stargazers_count', 0)
                        repo_stars[repo_url] = {
                            'stars': stars,
                            'full_name': repo_data.get('full_name', ''),
                            'description': repo_data.get('description', ''),
                            'language': repo_data.get('language', ''),
                            'created_at': repo_data.get('created_at', ''),
                            'updated_at': repo_data.get('updated_at', '')
                        }
                        print(f"é€²è¡ŒçŠ¶æ³: {i+1}/{len(unique_repos)} - {owner}/{repo_name}: {stars} stars")
                    else:
                        failed_repos.append(f"{repo_url} (Status: {response.status_code})")
                        
                    # APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
                    time.sleep(0.1)
                        
        except Exception as e:
            failed_repos.append(f"{repo_url} (Error: {str(e)})")
            continue
    
    if repo_stars:
        # ã‚¹ã‚¿ãƒ¼æ•°ã§ä¸¦ã³æ›¿ãˆ
        sorted_repos = sorted(repo_stars.items(), key=lambda x: x[1]['stars'], reverse=True)
        
        print("\n" + "="*80)
        print("ğŸŒŸ æœ€ã‚‚ã‚¹ã‚¿ãƒ¼æ•°ã®å¤šã„ãƒªãƒã‚¸ãƒˆãƒª TOP 10")
        print("="*80)
        
        for rank, (repo_url, info) in enumerate(sorted_repos[:10], 1):
            print(f"{rank:2d}. {info['full_name']}")
            print(f"    â­ Stars: {info['stars']:,}")
            print(f"    ğŸ”— URL: {repo_url}")
            print(f"    ğŸ“ Description: {info['description'][:100]}..." if info['description'] else "    ğŸ“ Description: N/A")
            print(f"    ğŸ’» Language: {info['language']}")
            print(f"    ğŸ“… Created: {info['created_at'][:10]}")
            print(f"    ğŸ”„ Updated: {info['updated_at'][:10]}")
            print()
        
        # çµ±è¨ˆæƒ…å ±
        total_stars = sum(info['stars'] for info in repo_stars.values())
        avg_stars = total_stars / len(repo_stars)
        
        print("="*80)
        print("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        print("="*80)
        print(f"æ¤œç´¢æˆåŠŸã—ãŸãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(repo_stars)}")
        print(f"æ¤œç´¢å¤±æ•—ã—ãŸãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(failed_repos)}")
        print(f"ç·ã‚¹ã‚¿ãƒ¼æ•°: {total_stars:,}")
        print(f"å¹³å‡ã‚¹ã‚¿ãƒ¼æ•°: {avg_stars:.1f}")
        
        if failed_repos:
            print(f"\nâš ï¸ æ¤œç´¢ã«å¤±æ•—ã—ãŸãƒªãƒã‚¸ãƒˆãƒª:")
            for failed in failed_repos[:5]:  # æœ€åˆã®5ã¤ã®ã¿è¡¨ç¤º
                print(f"  - {failed}")
            if len(failed_repos) > 5:
                print(f"  ... ãã®ä»– {len(failed_repos) - 5} ä»¶")
                
        return sorted_repos[0] if sorted_repos else None
    else:
        print("âŒ ã‚¹ã‚¿ãƒ¼æ•°ã‚’å–å¾—ã§ãã‚‹ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

if __name__ == '__main__':
    df = pd.read_parquet("../data_list/all_pull_request_local.parquet")
    top_repo = find_repo(df)
    
    if top_repo:
        repo_url, info = top_repo
        print(f"\nğŸ† æœ€ã‚‚ã‚¹ã‚¿ãƒ¼æ•°ã®å¤šã„ãƒªãƒã‚¸ãƒˆãƒª: {info['full_name']} ({info['stars']:,} stars)")

